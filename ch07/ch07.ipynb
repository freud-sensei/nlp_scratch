{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN을 사용한 문장 생성\n",
    "\n",
    "seq2seq: RNN 2개를 연결해 사용해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 생성 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 매 step마다 확률이 가장 높은 단어를 선택한다. (결정론적)\n",
    "* 각 후보 단어의 확률에 맞게 샘플링한다. (확률론적) <- 실습에선 이 방법으로\n",
    "\n",
    "어떤 방법이든, 결정된 단어가 step에 입력된다.\n",
    "\n",
    "원하는 만큼(아니면 종결기호가 나타가기 전까지) 반복한다.\n",
    "\n",
    "구현은 `rnnlm_gen.py`, `generate_text.py`를 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq (encoder-decoder)\n",
    "\n",
    "* Encoder: 출발어 문장을 고정 길이 벡터로 인코딩\n",
    "* Decoder: 인코딩된 문장 (encoder의 output h)을 도착어 문장으로 디코딩\n",
    "* 언어 번역 과정에서 Decoder의 각 timestep의 결과값은 다음 timestep의 input이 되기도 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**가변 길이 시계열 데이터**\n",
    "* 패딩: 원래 데이터에 의미없는 데이터를 채워 길이를 균일하게 전환\n",
    "* 입력 데이터가 패딩이라면 손실의 결과에 반영하지 않게끔 하기도 함\n",
    "\n",
    "구현은 `show_addition_dataset.py`, `seq2seq.py`, `train_seq2seq.py`를 보세요"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
